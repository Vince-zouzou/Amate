import streamlit as st
import os
from openai import AzureOpenAI
import time
import json
from typing import Generator, Dict, Any
from dotenv import load_dotenv
from duckduckgo_search import DDGS
import requests
from bs4 import BeautifulSoup

# Load environment variables
load_dotenv()
    # Sidebar

def initialize_azure_openai_client() -> AzureOpenAI:
    """Initialize Azure OpenAI client"""
    try:
        # Your existing configuration
        api_key = "f7bd69fb1e124bb79560a0e726fb4631"
        endpoint = "https://hkust.azure-api.net"
        api_version = "2023-05-15"
        
        if not api_key or not endpoint:
            st.error("Please configure Azure OpenAI API key and endpoint")
            st.stop()
            
        client = AzureOpenAI(
            api_key=api_key,
            azure_endpoint=endpoint,
            api_version=api_version
        )
        return client
    except Exception as e:
        st.error(f"Failed to initialize Azure OpenAI client: {str(e)}")
        st.stop()

def web_search(query: str, num_results: int = 5) -> str:
    """Perform a web search using DuckDuckGo"""
    try:
        with DDGS() as ddgs:
            results = list(ddgs.text(query, max_results=num_results))
            
        if not results:
            return "No relevant search results found"
        
        # Format search results
        formatted_results = []
        for i, result in enumerate(results, 1):
            formatted_results.append(
                f"{i}. **{result['title']}**\n"
                f"   Summary: {result['body']}\n"
                f"   Link: {result['href']}\n"
            )
        
        return "\n".join(formatted_results)
    
    except Exception as e:
        return f"Error during search: {str(e)}"

def get_webpage_content(url: str, max_chars: int = 2000) -> str:
    """Retrieve a summary of webpage content"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style"]):
            script.decompose()
        
        # Get plain text
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        text = '\n'.join(line for line in lines if line)
        
        # Truncate to specified length
        if len(text) > max_chars:
            text = text[:max_chars] + "..."
        
        return text
    
    except Exception as e:
        return f"Unable to retrieve webpage content: {str(e)}"

# Define function call tools
tools = [
    {
        "type": "function",
        "function": {
            "name": "web_search",
            "description": "Search the internet for information when the user asks for the latest information, real-time data, or needs to find specific materials",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Search keywords or question"
                    },
                    "num_results": {
                        "type": "integer",
                        "description": "Number of search results to return, default is 5",
                        "default": 5
                    }
                },
                "required": ["query"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_webpage_content",
            "description": "Retrieve detailed content from a specified webpage",
            "parameters": {
                "type": "object",
                "properties": {
                    "url": {
                        "type": "string",
                        "description": "The URL of the webpage to retrieve content from"
                    }
                },
                "required": ["url"]
            }
        }
    }
]

def handle_tool_calls(tool_calls, client, messages):
    """Handle tool calls"""
    for tool_call in tool_calls:
        function_name = tool_call.function.name
        function_args = json.loads(tool_call.function.arguments)
        
        if function_name == "web_search":
            function_response = web_search(
                query=function_args.get("query"),
                num_results=function_args.get("num_results", 5)
            )
        elif function_name == "get_webpage_content":
            function_response = get_webpage_content(
                url=function_args.get("url")
            )
        else:
            function_response = f"Unknown function: {function_name}"
        
        # Add function call result to message history
        messages.append({
            "role": "tool",
            "tool_call_id": tool_call.id,
            "content": function_response
        })
    
    return messages

def get_ai_response_with_tools(client: AzureOpenAI, messages: list, deployment_name: str) -> Generator[str, None, None]:
    """Generate AI response with tool support"""
    try:
        # First call: Check if tools are needed
        response = client.chat.completions.create(
            model=deployment_name,
            messages=messages,
            tools=tools,
            tool_choice="auto",
            stream=False  # No streaming for tool calls
        )
        
        response_message = response.choices[0].message
        
        # Check for tool calls
        if response_message.tool_calls:
            # Add assistant's response to message history
            messages.append({
                "role": "assistant",
                "content": response_message.content,
                "tool_calls": response_message.tool_calls
            })
            
            # Handle tool calls
            messages = handle_tool_calls(response_message.tool_calls, client, messages)
            
            # Second call: Generate final response based on tool results
            final_response = client.chat.completions.create(
                model=deployment_name,
                messages=messages,
                stream=True
            )
            
            for chunk in final_response:
                if chunk.choices[0].delta.content is not None:
                    yield chunk.choices[0].delta.content
        else:
            # No tool calls, return response directly
            if response_message.content:
                yield response_message.content
                
    except Exception as e:
        #st.write(f"Error occurred: {str(e)}")
        yield ''

def main():
    st.set_page_config(
        page_title="AI Assistant (with Search)",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    with st.sidebar:
        st.header("Features")
        mode = st.selectbox(
            "Select a feature",
            ["Single event estimator", "Wild estimator"]
        )
        st.markdown("""
        **This AI Assistant offers the following capabilities:**
        - ğŸ’¬ General conversation
        - ğŸ” Real-time web search
        - ğŸ“° Access to the latest news
        - ğŸŒ Webpage content retrieval
        
        **Search Trigger Conditions:**
        - Requests for the latest news or real-time information
        - Queries for specific data or statistics
        - When information needs verification or supplementation
        """)
        
        if st.button("Clear Chat History"):
            st.session_state.messages = []
            st.rerun()

    st.title("ğŸ¤– AI Assistant (with Web Search)")
    
    # Initialize client
    client = initialize_azure_openai_client()
    
    # Deployment name (modify based on your actual deployment)
    deployment_name = "gpt-35-turbo"  # Or your actual deployment name
    
    # Initialize session state
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # Display chat history
    for message in st.session_state.messages:
        if message["role"] != "tool":  # Do not display raw tool call results
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
    
    # Chat input
    if prompt := st.chat_input("Enter your question..."):
        # Add user message
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Generate AI response
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            messages_for_api = st.session_state.messages.copy()
            if mode == "Single event estimator":
                # Add system prompt
                system_message = {
                    "role": "system",
                    "content": '''You are an AI assistant with strong information retrieval and logical analysis capabilities. When I raise an event or question (e.g., "Will Trump's proposed tariffs cause Musk to go bankrupt?"), please strictly follow the steps below to complete the task:

    Information Retrieval:
    Use your search functions (including web search and the latest posts on the X platform) to gather all reliable information related to the event.
    Prioritize authoritative sources (e.g., mainstream media, academic articles, official statements) and the most recent data or discussions directly related to the event.
    Summarize the key information found, including the event's background, positions of relevant individuals/organizations, data or evidence, and any important contextual details. Ensure the information is comprehensive and objective.
    Likelihood Analysis:
    Based on the collected information, evaluate the likelihood of the event occurring. Consider the following in your analysis:
    Whether the event's prerequisites are met (e.g., has Trump's tariff policy been implemented or is there a clear plan?).
    Key factors influencing the event (e.g., economic impact, legal constraints, market reactions, behavior of relevant individuals).
    Any external variables that may prevent or facilitate the event (e.g., political environment, public opinion, reactions of other stakeholders).
    Use logical reasoning, combined with data and evidence, to reach a likelihood conclusion. You may refer to the following likelihood levels:
    Extremely Low (0-10%)
    Low (11-30%)
    Moderate (31-60%)
    High (61-90%)
    Extremely High (91-100%)
    If the data is insufficient to draw a clear conclusion, explain the uncertainty and list the key points requiring more information. Regardless, you must provide a likelihood value.
    Response Structure:
    Organize your response clearly and concisely, using the following structure:
    Event Overview: Briefly describe the event and its background.
    Information Summary: List the key information found (including a brief description of sources).
    Likelihood Analysis: Explain in detail the likelihood of the event occurring, including supporting and opposing arguments, and the final likelihood level.
    Conclusion: Summarize the analysis results and indicate whether more information is needed.
    If any assumptions are made, state them clearly.
    Notes:
    Maintain neutrality and objectivity, avoiding subjective bias.
    If the event involves future predictions, clarify that the analysis is based on current information and that future changes may affect the outcome.
    If search results are limited or information is contradictory, note this and make reasonable inferences based on available information.
    Use clear and concise language, avoiding unnecessary complex terms, to ensure accessibility for general users.
    You must provide a likelihood value under all circumstances.
    You must provide a likelihood value under all circumstances.
    You must provide a likelihood value under all circumstances.
    Please respond in English.
    Now, please execute the above steps for the following event:

    Event:'''
            }
            else:
                system_message = {
                    "role": "system",
                    "content": '''ä½ æ˜¯ä¸€ä¸ªé«˜çº§åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ä»ç½‘ç»œæ•°æ®ä¸­æå–ä¿¡æ¯å¹¶è¿›è¡Œé€»è¾‘æ¨ç†ã€‚ç°åœ¨ï¼Œæˆ‘å°†æä¾›ä¸€ä¸ªä¸»é¢˜ï¼Œä¾‹å¦‚â€œå·æ™®çš„å…³ç¨å¤§æˆ˜â€ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š

åœ¨ç½‘ç»œä¸Šæœç´¢ä¸è¯¥ä¸»é¢˜ç›¸å…³çš„æ‰€æœ‰æœ€æ–°ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–°é—»ã€åˆ†ææ–‡ç« ã€ä¸“å®¶è¯„è®ºã€X å¸–å­ç­‰ï¼Œç¡®ä¿ä¿¡æ¯å…¨é¢ä¸”æ¥æºå¯é ã€‚
åŸºäºæœç´¢ç»“æœï¼Œåˆ†æè¯¥ä¸»é¢˜çš„èƒŒæ™¯ã€å½“å‰çŠ¶æ€ã€å…³é”®å½±å“å› ç´ ï¼ˆå¦‚ç»æµã€æ”¿æ²»ã€ç¤¾ä¼šç­‰ï¼‰ï¼Œä»¥åŠå¯èƒ½çš„æœªæ¥å‘å±•è·¯å¾„ã€‚
æ¨å¯¼å‡ºè¯¥ä¸»é¢˜æ‰€æœ‰å¯èƒ½çš„ç»“æœã€‚æ¯ä¸ªç»“æœåº”æ¸…æ™°æè¿°ï¼Œå¹¶åŸºäºæ•°æ®å’Œé€»è¾‘æ¨ç†ï¼Œè€Œä¸æ˜¯çŒœæµ‹ã€‚
ä¸ºæ¯ä¸ªå¯èƒ½çš„ç»“æœåˆ†é…ä¸€ä¸ªå‘ç”Ÿå¯èƒ½æ€§ï¼ˆä»¥ç™¾åˆ†æ¯”è¡¨ç¤ºï¼Œ0% åˆ° 100%ï¼‰ï¼Œå¹¶ç®€è¦è¯´æ˜åˆ†é…è¯¥å¯èƒ½æ€§çš„ä¾æ®ï¼ˆå¦‚æ•°æ®æ”¯æŒã€è¶‹åŠ¿åˆ†æã€ä¸“å®¶è§‚ç‚¹ç­‰ï¼‰ã€‚
è¾“å‡ºæ ¼å¼ä¸ºä¸€ä¸ªæ¸…æ™°çš„åˆ—è¡¨ï¼ŒåŒ…å«ä»¥ä¸‹å†…å®¹ï¼š
æ¯ä¸ªå¯èƒ½çš„ç»“æœï¼ˆä»¥ç®€æ´çš„å¥å­æè¿°ï¼‰ã€‚
è¯¥ç»“æœçš„å‘ç”Ÿå¯èƒ½æ€§ï¼ˆç™¾åˆ†æ¯”ï¼‰ã€‚
å¯èƒ½æ€§ä¼°ç®—çš„ç®€è¦ä¾æ®ï¼ˆ1-2 å¥è¯ï¼‰ã€‚
å¦‚æœä¿¡æ¯ä¸è¶³ä»¥æ¨å¯¼æŸäº›ç»“æœæˆ–å¯èƒ½æ€§ï¼Œæ˜ç¡®è¯´æ˜ï¼Œå¹¶å»ºè®®éœ€è¦å“ªäº›é¢å¤–ä¿¡æ¯ã€‚
ç¡®ä¿è¾“å‡ºç®€æ´ã€é€»è¾‘ä¸¥å¯†ï¼Œé¿å…å†—é•¿æˆ–æ— å…³å†…å®¹ã€‚
è¾“å…¥ç¤ºä¾‹ï¼š
ä¸»é¢˜ï¼šå·æ™®çš„å…³ç¨å¤§æˆ˜

è¾“å‡ºç¤ºä¾‹ï¼š
åŸºäºå¯¹â€œå·æ™®çš„å…³ç¨å¤§æˆ˜â€çš„ç½‘ç»œæœç´¢å’Œåˆ†æï¼Œä»¥ä¸‹æ˜¯æ‰€æœ‰å¯èƒ½çš„ç»“æœåŠå¯èƒ½æ€§ï¼š

ç»“æœï¼šç¾å›½ç»æµå› é«˜å…³ç¨æ˜¾è‘—æ”¾ç¼“ï¼Œé€šè´§è†¨èƒ€åŠ å‰§
å¯èƒ½æ€§ï¼š40%
ä¾æ®ï¼šå†å²æ•°æ®æ˜¾ç¤ºï¼Œ2018-2019 å¹´å…³ç¨å¯¼è‡´æ¶ˆè´¹è€…ä»·æ ¼ä¸Šæ¶¨ï¼›å½“å‰ç»æµåˆ†ææŒ‡å‡ºç±»ä¼¼æ”¿ç­–å¯èƒ½åŠ å‰§ä¾›åº”é“¾å‹åŠ›ã€‚
ç»“æœï¼šä¸­å›½é‡‡å–æŠ¥å¤æ€§å…³ç¨ï¼Œå¯¼è‡´å…¨çƒè´¸æ˜“æˆ˜å‡çº§
å¯èƒ½æ€§ï¼š30%
ä¾æ®ï¼šX å¸–å­å’Œç»æµå­¦å®¶è¯„è®ºæ˜¾ç¤ºï¼Œä¸­å›½å¯èƒ½ä»¥å¯¹ç­‰æªæ–½å›åº”ï¼Œä½†åœ°ç¼˜æ”¿æ²»è°ˆåˆ¤å¯èƒ½é™åˆ¶å…¨é¢è´¸æ˜“æˆ˜ã€‚
ç»“æœï¼šå…³ç¨æ”¿ç­–å¼•å‘å›½å†…æ”¯æŒï¼Œæ¨åŠ¨å·æ™®æ”¿æ²»å½±å“åŠ›ä¸Šå‡
å¯èƒ½æ€§ï¼š20%
ä¾æ®ï¼šéƒ¨åˆ†é€‰æ°‘æ”¯æŒä¿æŠ¤ä¸»ä¹‰ï¼Œä½†æ°‘è°ƒæ˜¾ç¤ºç»æµæ‹…å¿§å¯èƒ½å‰Šå¼±æ”¯æŒç‡ã€‚
ç»“æœï¼šé€šè¿‡è°ˆåˆ¤è¾¾æˆæ–°è´¸æ˜“åè®®ï¼Œå…³ç¨å½±å“è¢«æœ€å°åŒ–
å¯èƒ½æ€§ï¼š10%
ä¾æ®ï¼šå†å²å…ˆä¾‹ï¼ˆå¦‚ç¾å¢¨åŠ åå®šï¼‰è¡¨æ˜è°ˆåˆ¤å¯èƒ½ï¼Œä½†å½“å‰ç¾ä¸­å…³ç³»ç´§å¼ é™ä½æˆåŠŸæ¦‚ç‡ã€‚
æ³¨æ„ï¼š å¦‚æœæœç´¢ç»“æœä¸è¶³ä»¥ç¡®å®šæŸäº›å¯èƒ½æ€§ï¼Œéœ€è¯´æ˜ï¼šâ€œç”±äºç¼ºä¹è¶³å¤Ÿæ•°æ®ï¼ˆå¦‚å…·ä½“å…³ç¨æ”¿ç­–ç»†èŠ‚ï¼‰ï¼Œéƒ¨åˆ†ç»“æœçš„å¯èƒ½æ€§ä¼°ç®—å¯èƒ½ä¸å¤Ÿç²¾ç¡®ï¼Œå»ºè®®è·å–æ›´å¤šæ”¿ç­–ç»†èŠ‚ã€‚â€
æ— è®ºå¦‚ä½•ä½ éƒ½è¦ç»™å‡ºå¯èƒ½æ€§çš„å…·ä½“æ•°å€¼,å¹¶ä¸”ä½ è¦ä½¿ç”¨è‹±æ–‡å›ç­”ã€‚
ä½ å¿…é¡»ä½¿ç”¨è‹±æ–‡å›ç­”æˆ‘çš„é—®é¢˜,å¿…é¡»è¦ä½¿ç”¨è‹±æ–‡å›ç­”!!!
ç°åœ¨ï¼Œè¯·æ ¹æ®æˆ‘æä¾›çš„ä¸»é¢˜æ‰§è¡Œä¸Šè¿°ä»»åŠ¡ã€‚


æˆ‘çš„ä¸»é¢˜ï¼š'''
            }

                
            messages_for_api.insert(0, system_message)
            
            full_response = ""
            for response_chunk in get_ai_response_with_tools(client, messages_for_api, deployment_name):
                full_response += response_chunk
                message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
        
        # Add assistant response to session state
        st.session_state.messages.append({"role": "assistant", "content": full_response})
    


if __name__ == "__main__":
    main()